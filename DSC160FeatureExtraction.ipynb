{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSC160FeatureExtraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI33f_23Ebtp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "#import imageio as io\n",
        "from skimage import io\n",
        "import skimage\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2hsv\n",
        "import scipy.misc\n",
        "from scipy import ndimage\n",
        "import scipy.misc\n",
        "from skimage import data, io\n",
        "from skimage.color import rgb2hsv\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from skimage import exposure\n",
        "from skimage.filters.rank import entropy\n",
        "from skimage.morphology import disk\n",
        "from skimage.color import rgb2gray\n",
        "import urllib.request\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import urllib.request\n",
        "from urllib.error import HTTPError\n",
        "\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPQhGEE8KOY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_and_clean_data(path):\n",
        "    df = pd.read_csv(path, encoding=\"ISO-8859-1\", usecols=[\"imdbId\", \"Title\", \"Genre\", \"Poster\"])\n",
        "    df.set_index([\"imdbId\"], inplace=True)\n",
        "    print(f\"Shape of the original dataset: {df.shape}\")\n",
        "    df.dropna(inplace=True)\n",
        "    print(f\"Shape after dropping rows with missing values: {df.shape}\")\n",
        "    df.drop_duplicates(subset=\"Poster\", keep=False, inplace=True)\n",
        "    print(f\"Shape after dropping rows with potentially misleading poster link: {df.shape}\\n\")\n",
        "    return df\n",
        "\n",
        "def add_year_variable(df):\n",
        "    re_year = re.compile(\"\\((\\d{4})\\)\")\n",
        "    df[\"year\"] = df.Title.map(lambda x: int(re_year.findall(x)[0]) if re_year.findall(x) else None)\n",
        "    print(f\"There are movies between {int(np.min(df.year))} and {int(np.max(df.year))} available in the dataset.\\n\")\n",
        "    return df\n",
        "\n",
        "def create_boolean_genres(df):\n",
        "    df[\"Genre\"] = df.Genre.map(lambda x: x.split(\"|\"))\n",
        "    all_genres = set([item for l in df.Genre for item in l])\n",
        "    print(f\"There are {len(all_genres)} genres in the dataset: {all_genres}\\n\")\n",
        "    for genre in all_genres:\n",
        "        new_var = \"is_\" + re.sub(r'\\W+', '', genre.lower())\n",
        "        df[new_var] = df.Genre.map(lambda x: genre in x)\n",
        "    df.drop([\"Genre\"], axis=1, inplace=True)\n",
        "    return df\n",
        "\n",
        "def extract_genre_data(df, genre=\"Action\"):\n",
        "    filter_var = \"is_\" + re.sub(r'\\W+', '', genre.lower())\n",
        "    df_genre = df.copy().loc[df[filter_var]]\n",
        "    print(f\"{genre} movies in the dataset: {df_genre.shape[0]}\\n\")\n",
        "    return df_genre\n",
        "\n",
        "def select_years(df, min_year=1950, max_year=2000, add_decades=True):\n",
        "    df_range = df.copy().loc[(df.year >= min_year) & (df.year < max_year)]\n",
        "    print(f\"Movies left between {min_year} and {max_year}: {df_range.shape[0]}\")\n",
        "    if add_decades:\n",
        "        df_range[\"decade\"] = df_range.year.apply(lambda x: str(int(x))[2] +\"0s\")\n",
        "        print(f\"Movies per decade in the dataset:\\n{df_range.decade.value_counts()}\\n\")\n",
        "    return df_range\n",
        "\n",
        "def sample_same_number_per_decade(df, use_test_sample=False):\n",
        "    min_number = 40 if use_test_sample else np.min(df.decade.value_counts())\n",
        "    df_sample = df.groupby(\"decade\").apply(lambda x: x.sample(min_number))\n",
        "    print(f\"Sample includes {min_number} movies per decade\")\n",
        "    return df_sample\n",
        "\n",
        "def create_train_and_test_dfs(df, prop_test=.2, strat = 'decade'):\n",
        "    if strat is not None:\n",
        "        strat = df[strat]\n",
        "    train, test = train_test_split(df, test_size=prop_test, stratify=strat)\n",
        "    print(f\"Number of movies in training data: {train.shape[0]}\")\n",
        "    print(f\"Number of movies in testing data:  {test.shape[0]}\\n\")\n",
        "    return {\"train\": train, \"test\": test}\n",
        "\n",
        "def create_folder_structure(image_folder=\"movie_posters\", splits=[\"train\", \"test\"], classes=None):\n",
        "    for s in splits:\n",
        "        for c in classes:\n",
        "            folder_name = \"/\".join([image_folder, s, c])\n",
        "            try:\n",
        "                os.makedirs(folder_name)\n",
        "            except FileExistsError:\n",
        "                print(f\"{folder_name} already exists.\")\n",
        "        print(\"\\n\")\n",
        "        \n",
        "def download_posters(dfs, image_folder=\"movie_posters\"):\n",
        "    for k, df in dfs.items():\n",
        "        print(f\"Starting with downloading files for {k}...\\n\")\n",
        "        already_downloaded = 0\n",
        "        http_errors = []\n",
        "        for index, movie in df.iterrows():\n",
        "            movie_id = str(index[1])\n",
        "            movie_decade = index[0]\n",
        "            file_name = movie_id + \".jpg\"\n",
        "            file_path = \"/\".join([image_folder, k, movie_decade, file_name])\n",
        "            if os.path.isfile(file_path):\n",
        "                already_downloaded += 1\n",
        "            else:\n",
        "                try:\n",
        "                    urllib.request.urlretrieve(movie.Poster, file_path)       \n",
        "                except HTTPError:\n",
        "                    http_errors.append(movie_id)\n",
        "        print(f\"{len(http_errors)} posters had an HTTPError.\")\n",
        "        print(f\"{already_downloaded} posters were downloaded before.\\n\")\n",
        "        count = 0\n",
        "        for root, dirs, files in os.walk(\"/\".join([image_folder, k])):\n",
        "            if len(dirs) == 0:\n",
        "                count += len(files)\n",
        "                print(f\"Number of pictures in {root}:\\t{len(files)}\")\n",
        "        print(f\"\\nTotal number of pictures available for {k}: {count}\\n\")\n",
        "\n",
        "def delete_black_and_white_posters(image_folder=None):\n",
        "    print(f\"\\nChecking for black and white pictures in {image_folder}...\")\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(image_folder):\n",
        "        if len(files) > 0:\n",
        "            for f in files:\n",
        "                file_path = \"/\".join([root, f])\n",
        "                if np.asarray(Image.open(file_path)).shape != (268, 182, 3):\n",
        "                    os.remove(file_path)\n",
        "                    count += 1\n",
        "    print(f\"Files without RGB and therefore deleted: {count}\")    \n",
        "    \n",
        "    \n",
        "### TO DOWNLOAD ALL ####\n",
        "def create_all_folders(image_folder=\"movie_posters\",name = 'all', classes=None):\n",
        "    for c in classes:\n",
        "        folder_name = \"/\".join([image_folder, name, c])\n",
        "        try:\n",
        "            os.makedirs(folder_name)\n",
        "        except FileExistsError:\n",
        "            print(f\"{folder_name} already exists.\")\n",
        "    print(\"\\n\")\n",
        "    \n",
        "def download_all(df, image_folder=\"movie_posters\", name = 'all'):\n",
        "    if not os.path.exists(\"/\".join([image_folder, name])):\n",
        "        os.mkdir(\"/\".join([image_folder, name]))\n",
        "    print(f\"Starting with all downloading files..\\n\")\n",
        "    already_downloaded = 0\n",
        "    http_errors = []\n",
        "    for index, movie in df.iterrows():\n",
        "        movie_id = str(index[1])\n",
        "        movie_decade = index[0]\n",
        "        file_name = movie_id + \".jpg\"\n",
        "        file_path = \"/\".join([image_folder, name, movie_decade, file_name])\n",
        "        if os.path.isfile(file_path):\n",
        "            already_downloaded += 1\n",
        "        else:\n",
        "            try:\n",
        "                urllib.request.urlretrieve(movie.Poster, file_path)       \n",
        "            except HTTPError:\n",
        "                http_errors.append(movie_id)\n",
        "    print(f\"{len(http_errors)} posters had an HTTPError.\")\n",
        "    print(f\"{already_downloaded} posters were downloaded before.\\n\")\n",
        "    count = 0\n",
        "    for root, dirs, files in os.walk(\"/\".join([image_folder, name])):\n",
        "        if len(dirs) == 0:\n",
        "            count += len(files)\n",
        "            print(f\"Number of pictures in {root}:\\t{len(files)}\")\n",
        "    #print(f\"\\nTotal number of pictures available for {k}: {count}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x55a4uAAExNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip 4.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7rSy9HOwmeI",
        "colab_type": "code",
        "outputId": "e40dd082-43c0-4fdd-b9bc-376e97fd0e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zM3Q1C6Xwilf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!unzip /content/AllPoster.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMdbrGyQKhmW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_stats(filename):\n",
        "    camera = io.imread(filename)\n",
        "    image_width = camera.shape[1]\n",
        "    image_height = camera.shape[0]\n",
        "    hsv_img = rgb2hsv(camera)\n",
        "    hue_img = hsv_img[:, :, 0]\n",
        "    saturation_img = hsv_img[:,:, 1]\n",
        "    value_img = hsv_img[:, :, 2]\n",
        "    mean_hue = np.mean(hue_img, axis=(0,1))\n",
        "    mean_saturation = np.mean(saturation_img, axis=(0,1))\n",
        "    mean_brightness = np.mean(value_img)\n",
        "    return [image_width, image_height, mean_hue, mean_saturation, mean_brightness]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWXPW6hsKjR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_colorfulness(image):\n",
        "    # split the image into its respective RGB components\n",
        "    (B, G, R) = cv2.split(image.astype(\"float\"))\n",
        "    # compute rg = R - G\n",
        "    rg = np.absolute(R - G)\n",
        "    # compute yb = 0.5 * (R + G) - B\n",
        "    yb = np.absolute(0.5 * (R + G) - B)\n",
        "    # compute the mean and standard deviation of both `rg` and `yb`\n",
        "    (rbMean, rbStd) = (np.mean(rg), np.std(rg))\n",
        "    (ybMean, ybStd) = (np.mean(yb), np.std(yb))\n",
        "    # combine the mean and standard deviations\n",
        "    stdRoot = np.sqrt((rbStd ** 2) + (ybStd ** 2))\n",
        "    meanRoot = np.sqrt((rbMean ** 2) + (ybMean ** 2))\n",
        "    # derive the \"colorfulness\" metric and return it\n",
        "    return stdRoot + (0.3 * meanRoot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNp3ebm1Klzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcDGenergy(img):\n",
        "    # from from https://stackoverflow.com/a/48974892\n",
        "\n",
        "    #convert from uint8 to int64 to prevent overflow problems\n",
        "    arr = np.array(img, dtype = int)\n",
        "\n",
        "    #calculate squared difference ((x-1, y) - (x+1, y))^2 for each R, G and B pixel\n",
        "    deltaX2 = np.square(np.roll(arr, -1, axis = 0) - np.roll(arr, 1, axis = 0))\n",
        "\n",
        "    #same for y axis\n",
        "    deltaY2 = np.square(np.roll(arr, -1, axis = 1) - np.roll(arr, 1, axis = 1))\n",
        "\n",
        "    #add R, G and B values for each pixel, then add x- and y-shifted values\n",
        "    dualEnergy = np.sum(deltaX2, axis = 2) + np.sum(deltaY2, axis = 2)\n",
        "    return dualEnergy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L71U6OpKolQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def edginess(filename):\n",
        "    painting = io.imread(filename)\n",
        "    hsv_img = rgb2hsv(painting)\n",
        "    value_img = hsv_img[:, :, 2]\n",
        "    sobel_x = ndimage.sobel(value_img, axis=0, mode='constant')\n",
        "    sobel_y = ndimage.sobel(value_img, axis=1, mode='constant')\n",
        "    edge_image = np.hypot(sobel_x, sobel_y)\n",
        "    sum_of_edge_image = np.sum(edge_image)/ (edge_image.size)\n",
        "    mean_of_edge_image = edge_image.mean()\n",
        "\n",
        "    temp = exposure.rescale_intensity(edge_image, out_range=(-1.0, 1.0))\n",
        "\n",
        "    edges = skimage.img_as_ubyte(np.clip(temp, -1, 1))\n",
        "\n",
        "    # Probabilistic Hough Transform\n",
        "    minLineLength = 400\n",
        "    maxLineGap = 10\n",
        "\n",
        "    lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
        "    #result = abstract.copy()\n",
        "    #\n",
        "    #for x in range(0, len(lines)):    \n",
        "    #    for x1,y1,x2,y2 in lines[x]:\n",
        "    #        cv2.line(result,(x1,y1),(x2,y2),(0,255,255),5)\n",
        "\n",
        "    # cv2.imwrite('houghlines5.jpg',edges)\n",
        "\n",
        "    #img = landscape\n",
        "    gray_img = rgb2gray(painting)\n",
        "    entr_img = entropy(gray_img, disk(10))\n",
        "    #io.imshow(entr_img)\n",
        "\n",
        "    #dgEnergy = calcDGenergy(painting)\n",
        "    return sum_of_edge_image, mean_of_edge_image, len(lines), entr_img.mean()#,  dgEnergy.min(),  dgEnergy.max(),  dgEnergy.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPf0qdqdJ8Yb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RwfXgQVJQKb",
        "colab_type": "code",
        "outputId": "3bba3e3f-42cc-49ce-a72c-ef53567c4ae7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import time\n",
        "count = 0\n",
        "start = time.time()\n",
        "ids = []\n",
        "widths = []\n",
        "heights = []\n",
        "hues = []\n",
        "saturations = []\n",
        "brightnesses = []\n",
        "corners_list = []\n",
        "colorfulness_list = []\n",
        "sums_edges = []\n",
        "means_edges = []\n",
        "num_lines = []\n",
        "entropy_means = []\n",
        "dg_image_energy_mins = []\n",
        "dg_image_energy_maxs = []\n",
        "dg_image_energy_means = []\n",
        "for i in os.listdir():\n",
        "    try:\n",
        "        width, height, hue, saturation, brightness = calc_stats(i)\n",
        "        #ids.append(i.partition(\".\")[0])\n",
        "        #widths.append(width)\n",
        "        #heights.append(height)\n",
        "        #hues.append(hue)\n",
        "        #saturations.append(saturation)\n",
        "        #brightnesses.append(brightness)\n",
        "\n",
        "        # Colourfulness\n",
        "        img = cv2.imread(i)\n",
        "        # calculating colorfulness\n",
        "        colorfulness = image_colorfulness(img)\n",
        "        #colorfulness_list.append(colorfulness)\n",
        "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "        # find Harris corners\n",
        "        gray = np.float32(gray)\n",
        "        dst = cv2.cornerHarris(gray,2,3,0.04)\n",
        "        dst = cv2.dilate(dst,None)\n",
        "        ret, dst = cv2.threshold(dst,0.01*dst.max(),255,0)\n",
        "        dst = np.uint8(dst)\n",
        "        # find centroids\n",
        "        ret, labels, stats, centroids = cv2.connectedComponentsWithStats(dst)\n",
        "        # define the criteria to stop and refine the corners\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.001)\n",
        "        corners = cv2.cornerSubPix(gray,np.float32(centroids),(5,5),(-1,-1),criteria)\n",
        "        #corners_list.append(len(corners))\n",
        "\n",
        "        sum_edges, mean_edges, lines, mean_ent = edginess(i)\n",
        "        sums_edges.append(sum_edges)\n",
        "        means_edges.append(mean_edges)\n",
        "        num_lines.append(lines)\n",
        "        entropy_means.append(mean_ent)\n",
        "\n",
        "        dgEnergy = calcDGenergy(io.imread(i))\n",
        "        en_min, en_max, en_mean = dgEnergy.min(),  dgEnergy.max(),  dgEnergy.mean()\n",
        "        dg_image_energy_mins.append(en_min)\n",
        "        dg_image_energy_maxs.append(en_max)\n",
        "        dg_image_energy_means.append(en_mean)\n",
        "        ids.append(i.partition(\".\")[0])\n",
        "        widths.append(width)\n",
        "        heights.append(height)\n",
        "        hues.append(hue)\n",
        "        saturations.append(saturation)\n",
        "        brightnesses.append(brightness)\n",
        "        colorfulness_list.append(colorfulness)\n",
        "        corners_list.append(len(corners))\n",
        "        count += 1\n",
        "        #if count % 10 == 0:\n",
        "        #  print(\"You're at: \" + str(count))\n",
        "    except:\n",
        "        continue\n",
        "        \n",
        "end = time.time()\n",
        "print(\"Time Taken: \" + str(end - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/skimage/filters/rank/generic.py:119: UserWarning: Possible precision loss converting image of type float64 to uint8 as required by rank filters. Convert manually using skimage.util.img_as_ubyte to silence this warning.\n",
            "  out_dtype)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time Taken: 8872.638138771057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aqJWr7MSrk_",
        "colab_type": "code",
        "outputId": "ed15fe35-80bf-4b15-b7d6-64399454a197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "new_df = pd.DataFrame()\n",
        "new_df[\"imdbId\"] = ids\n",
        "new_df[\"Width\"] = widths\n",
        "new_df[\"Height\"] = heights\n",
        "new_df[\"Hue\"] = hues\n",
        "new_df[\"Saturation\"] = saturations\n",
        "new_df[\"Brightness\"] = brightnesses\n",
        "new_df[\"Colourfulness\"] = colorfulness_list\n",
        "new_df[\"Corners\"] = corners_list\n",
        "new_df[\"Edginess\"] = means_edges\n",
        "new_df[\"Number Of Lines (Hough)\"] = num_lines\n",
        "new_df[\"Mean Entropy\"] = entropy_means\n",
        "new_df[\"DG Image Energy Minimum\"] = dg_image_energy_mins\n",
        "new_df[\"DG Image Energy Maximum\"] = dg_image_energy_maxs\n",
        "new_df[\"DG Image Energy Mean\"] = dg_image_energy_means\n",
        "new_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>imdbId</th>\n",
              "      <th>Width</th>\n",
              "      <th>Height</th>\n",
              "      <th>Hue</th>\n",
              "      <th>Saturation</th>\n",
              "      <th>Brightness</th>\n",
              "      <th>Colourfulness</th>\n",
              "      <th>Corners</th>\n",
              "      <th>Edginess</th>\n",
              "      <th>Number Of Lines (Hough)</th>\n",
              "      <th>Mean Entropy</th>\n",
              "      <th>DG Image Energy Minimum</th>\n",
              "      <th>DG Image Energy Maximum</th>\n",
              "      <th>DG Image Energy Mean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>268978</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.289566</td>\n",
              "      <td>0.317307</td>\n",
              "      <td>0.493287</td>\n",
              "      <td>41.523655</td>\n",
              "      <td>48</td>\n",
              "      <td>0.435260</td>\n",
              "      <td>1</td>\n",
              "      <td>5.767977</td>\n",
              "      <td>0</td>\n",
              "      <td>356123</td>\n",
              "      <td>8038.865057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30973</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.268064</td>\n",
              "      <td>0.396460</td>\n",
              "      <td>0.761431</td>\n",
              "      <td>93.641859</td>\n",
              "      <td>169</td>\n",
              "      <td>0.701259</td>\n",
              "      <td>4</td>\n",
              "      <td>5.182376</td>\n",
              "      <td>0</td>\n",
              "      <td>317807</td>\n",
              "      <td>19729.438576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23686</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.182442</td>\n",
              "      <td>0.319706</td>\n",
              "      <td>0.632708</td>\n",
              "      <td>37.933190</td>\n",
              "      <td>152</td>\n",
              "      <td>0.940084</td>\n",
              "      <td>8</td>\n",
              "      <td>6.557065</td>\n",
              "      <td>0</td>\n",
              "      <td>351213</td>\n",
              "      <td>26105.511030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2017561</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.156557</td>\n",
              "      <td>0.440561</td>\n",
              "      <td>0.672142</td>\n",
              "      <td>57.595658</td>\n",
              "      <td>111</td>\n",
              "      <td>0.646836</td>\n",
              "      <td>4</td>\n",
              "      <td>6.454978</td>\n",
              "      <td>3</td>\n",
              "      <td>322862</td>\n",
              "      <td>13146.240323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>116479</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.242190</td>\n",
              "      <td>0.442489</td>\n",
              "      <td>0.294204</td>\n",
              "      <td>39.941220</td>\n",
              "      <td>100</td>\n",
              "      <td>0.414149</td>\n",
              "      <td>7</td>\n",
              "      <td>5.008403</td>\n",
              "      <td>0</td>\n",
              "      <td>224340</td>\n",
              "      <td>5427.131745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30752</th>\n",
              "      <td>82769</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.486926</td>\n",
              "      <td>0.453615</td>\n",
              "      <td>0.412819</td>\n",
              "      <td>47.597628</td>\n",
              "      <td>73</td>\n",
              "      <td>1.112720</td>\n",
              "      <td>19</td>\n",
              "      <td>6.520898</td>\n",
              "      <td>0</td>\n",
              "      <td>383084</td>\n",
              "      <td>33236.516402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30753</th>\n",
              "      <td>115976</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.431284</td>\n",
              "      <td>0.527088</td>\n",
              "      <td>0.462169</td>\n",
              "      <td>86.109456</td>\n",
              "      <td>40</td>\n",
              "      <td>0.446330</td>\n",
              "      <td>1</td>\n",
              "      <td>5.877357</td>\n",
              "      <td>0</td>\n",
              "      <td>268066</td>\n",
              "      <td>6600.868132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30754</th>\n",
              "      <td>4311466</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.218411</td>\n",
              "      <td>0.285973</td>\n",
              "      <td>0.674517</td>\n",
              "      <td>35.157194</td>\n",
              "      <td>83</td>\n",
              "      <td>0.413087</td>\n",
              "      <td>3</td>\n",
              "      <td>5.788535</td>\n",
              "      <td>0</td>\n",
              "      <td>300655</td>\n",
              "      <td>6276.040225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30755</th>\n",
              "      <td>5210048</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.216408</td>\n",
              "      <td>0.488336</td>\n",
              "      <td>0.499522</td>\n",
              "      <td>62.828648</td>\n",
              "      <td>140</td>\n",
              "      <td>0.769391</td>\n",
              "      <td>6</td>\n",
              "      <td>6.410104</td>\n",
              "      <td>0</td>\n",
              "      <td>343819</td>\n",
              "      <td>19300.933615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30756</th>\n",
              "      <td>93578</td>\n",
              "      <td>182</td>\n",
              "      <td>268</td>\n",
              "      <td>0.288241</td>\n",
              "      <td>0.347927</td>\n",
              "      <td>0.560187</td>\n",
              "      <td>53.495349</td>\n",
              "      <td>130</td>\n",
              "      <td>0.680379</td>\n",
              "      <td>3</td>\n",
              "      <td>6.137767</td>\n",
              "      <td>0</td>\n",
              "      <td>317360</td>\n",
              "      <td>15517.005659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30757 rows Ã— 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        imdbId  Width  ...  DG Image Energy Maximum  DG Image Energy Mean\n",
              "0       268978    182  ...                   356123           8038.865057\n",
              "1        30973    182  ...                   317807          19729.438576\n",
              "2        23686    182  ...                   351213          26105.511030\n",
              "3      2017561    182  ...                   322862          13146.240323\n",
              "4       116479    182  ...                   224340           5427.131745\n",
              "...        ...    ...  ...                      ...                   ...\n",
              "30752    82769    182  ...                   383084          33236.516402\n",
              "30753   115976    182  ...                   268066           6600.868132\n",
              "30754  4311466    182  ...                   300655           6276.040225\n",
              "30755  5210048    182  ...                   343819          19300.933615\n",
              "30756    93578    182  ...                   317360          15517.005659\n",
              "\n",
              "[30757 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWv-NzCLcNCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df.to_csv(\"All_Posters_Features.csv\")\n",
        "files.download(\"All_Posters_Features.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-WPN6_5dIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}